<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>sy</title>

  <meta name="author" content="Samir Yitzhak Gadre">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.ico">
</head>

<body onload="toggleNews();toggleNews()">
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Samir Yitzhak Gadre</name>
                  </p>
                  <p>
                    I am a 2nd year Ph.D. student at Columbia University studying how models pre-trained on internet
                    data can be used in embodied settings (e.g., robot navigation and manipulation). I am privileged to
                    be advised by <a href="https://www.cs.columbia.edu/~shurans/">Shuran Song</a>. I am also lucky to
                    receive mentorship from <a href="https://ehsanik.github.io/">Kiana Ehsani</a> and <a
                      href="https://roozbehm.info/">Roozbeh Mottaghi</a>. My doctoral work is supported by a Columbia
                    presidential fellowship and an NSF graduate research fellowship.
                  </p>
                  Before Columbia, I was a software engineer at <a
                    href="https://www.microsoft.com/en-us/hololens">Microsoft HoloLens</a>. I was on the Object
                  Understanding team, where I was lucky to work with <a
                    href="https://www.linkedin.com/in/harpreet-sawhney-2b024b28/">Harpreet Sawhney</a> and <a
                    href="https://www.linkedin.com/in/ning-xu-5a687896/">Ning Xu</a> on <a
                    href="https://azure.microsoft.com/en-us/services/object-anchors/#overview">Object Anchors</a>. With
                  their support, I developed a passion for computer vision.
                  <p>
                    Prior to Microsoft, I was a Computer Science undergrad at Brown University. I had a fantastic
                    experience working with <a href="http://cs.brown.edu/people/gdk/">George Konidaris</a> and <a
                      href="http://cs.brown.edu/people/stellex/">Stefanie Tellex</a> on augmented reality robot programming and learning
                    from demonstration.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:sy@cs.columbia.edu">Email</a> &nbsp/&nbsp
                    <!-- <a href="data/gadre_cv.pdf">CV</a> &nbsp|&nbsp -->
                    <a href="https://scholar.google.com/citations?user=oAhlg9gAAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://twitter.com/sy_gadre">Twitter</a>
                    <!-- <a href="data/gadre_cv.pdf">CV</a> -->
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/profile.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>



          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>News</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              <ul>
                <li>[May 2022] Returning to <a href="https://prior.allenai.org/">AI2
                  PRIOR</a> for another internship.
                <li>[Mar 2022] New preprint: <a href="https://arxiv.org/abs/2203.10421">CLIP on Wheels (CoW)</a>.
                <li>[Mar 2022] New preprint: <a href="https://arxiv.org/abs/2203.05482">Model soups</a>, led by <a href="https://mitchellnw.github.io/">Mitchell Wortsman</a> (ICML 2022).
                <li>[Mar 2022] New preprint: <a href="https://arxiv.org/abs/2203.17251">Continuous Scene Representations</a>, a
                  collaboration with AI2 (CVPR 2022).
                <li>[June 2021] Started an internship with the amazing folks at <a href="https://prior.allenai.org/">AI2
                    PRIOR</a>.
                <li>[May 2021] New preprint: <a href="https://arxiv.org/abs/2105.01047">Act the Part</a> (ICCV 2021).
                <li>[Sept 2020] Joined Shuran Song's group at Columbia. Excited to be a Ph.D. student!</li>
                <span id="moreNews">
                  <li>[July 2020] Promoted to Software Engineer II at Microsoft HoloLens.</li>
                  <li>[May 2019] Presented our robot programing mixed reality work at ICRA 2019.</li>
                  <li>[Feb 2019] Joined the Object Understanding team at Microsoft HoloLens.</li>
                  <li>[Oct 2018] Spoke at the <a
                      href="https://robotics.cs.washington.edu/colloquium/archive/18au/">University of Washington
                      robotics colloquium</a> about mixed reality human-robot interaction.</li>
                  <li>[May 2018] Graduated from Brown with an Sc.B. in computer science (with honors) and an A.B. in
                    engineering.</li>
                </span>
                <div onclick="toggleNews()" id="moreNewsBtn" class="showBtn"><a>Show more...</a></div>
                <div onclick="toggleNews()" id="lessNewsBtn" class="showBtn"><a>Show less...</a></div>
                <div style="clear: both;"></div>
              </ul>

            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Publications and Pre-Prints</heading>
                  <br> (* indicates equal contribution)
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>


              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/cow.gif" , height="120" , width="180">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2203.10421">
                    <papertitle>CLIP on Wheels: Zero-shot Object Navigation as Object Localization and Exploration
                    </papertitle>
                  </a>
                  <br>
                  <strong>Samir Yitzhak Gadre</strong>,
                  <a href="https://mitchellnw.github.io/">Mitchell Wortsman</a>,
                  <a href="http://gabrielilharco.com/">Gabriel Ilharco</a>,
                  <a href="https://people.csail.mit.edu/ludwigs/">Ludwig Schmidt</a>,
                  <a href="https://www.cs.columbia.edu/~shurans/">Shuran Song</a>
                  <br>
                  <em>arXiv</em>, 2022
                  <br>
                  <a href="data/gadre2022cow.bib">bibtex</a> | More coming soon!
                  <p>
                    We study how to turn existing zero-shot vision-and-language models (e.g., CLIP) into zero-shot
                    object navigators. We test directly on Habitat and RoboTHOR benchmarks.
                  </p>
                </td>
              </tr>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/soup.jpeg" width="180" height="120">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2203.05482">
                    <papertitle>Model soups: averaging weights of multiple fine-tuned models improves accuracy without
                      increasing inference time</papertitle>
                  </a>
                  <br>
                  <a href="https://mitchellnw.github.io/">Mitchell Wortsman</a>,
                  <a href="http://gabrielilharco.com/">Gabriel Ilharco</a>,
                  <strong>Samir Yitzhak Gadre</strong>,
                  <a href="https://twitter.com/beccaroelofs">Rebecca Roelofs</a>,
                  <a href="https://raphagl.com/">Raphael Gontijo-Lopes</a>,
                  <a href="http://www.arimorcos.com/">Ari S. Morcos</a>,
                  <a href="https://hsnamkoong.github.io/">Hongseok Namkoong</a>,
                  <a href="https://homes.cs.washington.edu/~ali/">Ali Farhadi</a>,
                  <a href="https://www.cs.tau.ac.il/~ycarmon/">Yair Carmon*</a>,
                  <a href="https://simonster.com/">Simon Kornblith*</a>,
                  <a href="https://people.csail.mit.edu/ludwigs/">Ludwig Schmidt*</a>
                  <br>
                  <em>ICML</em>, 2022
                  <br>
                  <a href="data/wortsman2022soups.bib">bibtex</a> | More coming soon!
                  <!-- <a href="https://atp.cs.columbia.edu/">website (with demo!)</a> -->
                  <p>
                    We average the weights of many models (ingredients) fine-tuned with different hyperparameters. The
                    resulting soup outperforms the individual ingredients.
                  </p>
                </td>
              </tr>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/csr.jpg" width="180" height="120">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2203.17251">
                    <papertitle>Continuous Scene Representations for Embodied AI</papertitle>
                  </a>
                  <br>
                  <strong>Samir Yitzhak Gadre</strong>,
                  <a href="https://ehsanik.github.io/">Kiana Ehsani</a>,
                  <a href="https://www.cs.columbia.edu/~shurans/">Shuran Song</a>,
                  <a href="https://roozbehm.info/">Roozbeh Mottaghi</a>
                  <br>
                  <em>CVPR</em>, 2022
                  <br>
                  <a href="data/gadre2022csr.bib">bibtex</a> | <a
                    href="https://prior.allenai.org/projects/csr">website</a> | <a
                    href="https://github.com/allenai/CSR">code</a>
                  <p>
                    We employ a contrastive loss to embed relationships between objects as features. We show how our
                    representation can be used downstream for visual room rearrangement without any additional training.
                    <!-- We learn multi-step interaction with articulated objects to (1) discover the number of parts and (2) find part segmentation masks, all without semantic labels. -->
                  </p>
                </td>
              </tr>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/atp.jpeg">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2105.01047">
                    <papertitle>Act the Part: Learning Interaction Strategies for Articulated Object Part Discovery
                    </papertitle>
                  </a>
                  <br>
                  <strong>Samir Yitzhak Gadre</strong>,
                  <a href="https://ehsanik.github.io/">Kiana Ehsani</a>,
                  <a href="https://www.cs.columbia.edu/~shurans/">Shuran Song</a>
                  <br>
                  <em>ICCV</em>, 2021
                  <br>
                  <a href="data/gadre2021act.bib">bibtex</a> |
                  <a href="https://atp.cs.columbia.edu/">website (with demo!)</a>
                  <p>
                    We learn multi-step interaction with articulated objects to (1) discover the number of parts and (2)
                    find part segmentation masks, all without semantic labels.
                  </p>
                </td>
              </tr>

              <tr onmouseout="end_user_stop()" onmouseover="end_user_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/end_user.gif">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="http://cs.brown.edu/people/gdk/pubs/end_user_prog_mr.pdf">
                    <papertitle>End-User Robot Programming Using Mixed Reality</papertitle>
                  </a>
                  <br>
                  <strong>Samir Yitzhak Gadre</strong>,
                  <a href="http://cs.brown.edu/people/er35/">Eric Rosen</a>,
                  <a href="https://www.linkedin.com/in/garychien/">Gary Chien</a>,
                  <a href="https://www.elizabethkphillips.com/">Elizabeth Phillips</a>,
                  <a href="http://cs.brown.edu/people/stellex/">Stefanie Tellex</a>,
                  <a href="http://cs.brown.edu/people/gdk/">George Konidaris</a>
                  <br>
                  <em>ICRA</em>, 2019
                  <br>
                  <a href="data/Gadre2019.bib">bibtex</a>
                  <p>
                    Mixed reality robot programming interface for pick-and-place tasks.
                  </p>
                </td>
              </tr>


              <tr onmouseout="lfd_stop()" onmouseover="lfd_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/lfd.gif">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="http://cs.brown.edu/research/pubs/theses/ugrad/2018/gadre.samir.pdf">
                    <papertitle>Teaching Robots Using Mixed Reality</papertitle>
                  </a>
                  <br>
                  <strong>Samir Yitzhak Gadre</strong>
                  <br>
                  <em>Brown University Undergraduate Honors Thesis</em>, 2018
                  <br>
                  <a href="data/Gadre2018.bib">bibtex</a>
                  <p>
                    Mixed reality learning from demonstration system for pick-and-place tasks.
                  </p>
                </td>
              </tr>

              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                  <tr>
                    <td>
                      <heading>Service</heading>
                    </td>
                  </tr>
                </tbody>
              </table>
              <table width="100%" align="center" border="0" cellpadding="20">
                <tbody>
                  <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/review.jpg" height="166" ,
                        width="166"></td>
                    <td width="75%" valign="center">
                      ECCV 2020; ICML 2022; IROS 2022
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/columbia.jpg" height="166"
                        , width="166"></td>
                    <td width="75%" valign="center">
                      Pre-submission Application Review (PAR); co-organizer, fall 2021.
                      <br>
                      <br>
                      <a href="https://www.womeninscienceatcolumbia.org/">WiSC</a>; mentor, fall 2020, spring 2021.
                      <br>
                      <br>
                      PAR; application reader, fall 2020.
                      <br>
                      <br>
                      <a href="https://sites.google.com/view/coms4733-fall2020/home?pli=1&authuser=1">COMS 4733:
                        Computational Aspects of Robotics</a>; Graduate Teaching Assistant, fall 2020.
                      <br>
                      <br>
                      COMS 6998: Topics in Robot Learning; Graduate Teaching Assistant, spring 2021.
                      <a></a>
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/brown_cs.jpg"></td>
                    <td width="75%" valign="center">
                      <a href="http://cs.brown.edu/courses/cs016/">CS16: Algorithms and Data Structures</a>; Teaching
                      Assistant, spring 2018.
                      <br>
                      <br>
                      <a href="http://cs.brown.edu/courses/cs015/">CS15: Object Oriented Programming</a>; Teaching
                      Assistant, fall 2016.

                    </td>
                  </tr>
                </tbody>
              </table>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:0px">
                      <br>
                      <br>
                      <br>
                      <br>
                      <br>
                      <br>
                      <br>
                      <br>
                      <br>
                      <br>
                      <br>
                      <p style="text-align:right;font-size:small;">
                        Template modified from the <a href="https://github.com/jonbarron/jonbarron_website">Jon
                          Barron</a> original.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>
        </td>
      </tr>
  </table>

  <script>
    function toggleNews() {
      var moreNews = document.getElementById("moreNews");
      var moreNewsBtn = document.getElementById("moreNewsBtn");
      var lessNewsBtn = document.getElementById("lessNewsBtn");
      if (moreNewsBtn.style.display === "none") {
        moreNews.style.display = "none";
        moreNewsBtn.style.display = "inline";
        lessNewsBtn.style.display = "none";
      } else {
        moreNews.style.display = "inline";
        moreNewsBtn.style.display = "none";
        lessNewsBtn.style.display = "inline";
      }
    }
  </script>
</body>

</html>
